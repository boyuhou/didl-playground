{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import d2l\n",
    "from mxnet import gluon, init, npx\n",
    "from mxnet.gluon import nn\n",
    "import pandas as pd; pd.__version__\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_mnist(batch_size, resize=None):\n",
    "    dataset = gluon.data.vision\n",
    "    trans = [dataset.transforms.Resize(resize)] if resize else []\n",
    "    trans.append(dataset.transforms.ToTensor())\n",
    "    trans = dataset.transforms.Compose(trans)\n",
    "    mnist_train = dataset.MNIST(train=True).transform_first(trans, lazy=False)\n",
    "    mnist_test = dataset.MNIST(train=False).transform_first(trans, lazy=False)\n",
    "    return (gluon.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                                  num_workers=d2l.get_dataloader_workers()),\n",
    "            gluon.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                                  num_workers=d2l.get_dataloader_workers()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = load_data_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(\n",
    "    nn.Dense(256, activation='relu'),\n",
    "    nn.Dense(10)\n",
    ")\n",
    "net.initialize(init.Normal(sigma=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net, train_iter, loss, updater):\n",
    "    metric = d2l.Accumulator(3)  # train_loss_sum, train_acc_sum, num_examples\n",
    "    if isinstance(updater, gluon.Trainer):\n",
    "        updater = updater.step\n",
    "    for X, y in train_iter:\n",
    "        # Compute gradients and update parameters\n",
    "        with d2l.autograd.record():\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "        l.backward()\n",
    "        updater(X.shape[0])\n",
    "        metric.add(float(l.sum()), d2l.accuracy(y_hat, y), y.size)\n",
    "    # Return training loss and training accuracy\n",
    "    return metric[0]/metric[2], metric[1]/metric[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, train_iter, test_iter, loss, num_epochs, updater):\n",
    "#     animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
    "#                         ylim=[0.0, 1.0],\n",
    "#                         legend=['train loss', 'train acc', 'test acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch(net, train_iter, loss, updater)\n",
    "        test_acc = d2l.evaluate_accuracy(net, test_iter)\n",
    "        print(f'iter: {epoch} Test Accuracy: {test_acc}')\n",
    "        #animator.add(epoch+1, train_metrics+(test_acc,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 Test Accuracy: 0.8868\n",
      "iter: 1 Test Accuracy: 0.9102\n",
      "iter: 2 Test Accuracy: 0.9183\n",
      "iter: 3 Test Accuracy: 0.9233\n",
      "iter: 4 Test Accuracy: 0.9325\n",
      "iter: 5 Test Accuracy: 0.9383\n",
      "iter: 6 Test Accuracy: 0.9413\n",
      "iter: 7 Test Accuracy: 0.9449\n",
      "iter: 8 Test Accuracy: 0.9477\n",
      "iter: 9 Test Accuracy: 0.948\n",
      "iter: 10 Test Accuracy: 0.9535\n",
      "iter: 11 Test Accuracy: 0.9558\n",
      "iter: 12 Test Accuracy: 0.9581\n",
      "iter: 13 Test Accuracy: 0.9586\n",
      "iter: 14 Test Accuracy: 0.9618\n",
      "iter: 15 Test Accuracy: 0.9636\n",
      "iter: 16 Test Accuracy: 0.9644\n",
      "iter: 17 Test Accuracy: 0.9646\n",
      "iter: 18 Test Accuracy: 0.9665\n",
      "iter: 19 Test Accuracy: 0.9675\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "train_model(net, train_iter, test_iter, loss, num_epochs, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
