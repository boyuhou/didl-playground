{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwongkee\\Anaconda3\\envs\\tf2\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "RESHAPED = 28 * 28\n",
    "x_train = x_train.reshape(60000, RESHAPED)\n",
    "x_test = x_test.reshape(10000, RESHAPED)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, NB_CLASSES)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = r'C:\\\\cmder\\\\logs\\\\fit\\\\{timestamp}_{tag}'#.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")),\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_layer (Dense)          (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_layer2 (Dense)         (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_layer3 (Dense)         (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(N_HIDDEN, \n",
    "                                input_shape=(RESHAPED,),\n",
    "                                name='dense_layer', \n",
    "                                activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(N_HIDDEN, \n",
    "                                input_shape=(RESHAPED,),\n",
    "                                name='dense_layer2', \n",
    "                                activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(NB_CLASSES, \n",
    "                                input_shape=(RESHAPED,),\n",
    "                                name='dense_layer3', \n",
    "                                activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "  128/48000 [..............................] - ETA: 9:51 - loss: 0.1821 - accuracy: 0.9609WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.103525). Check your callbacks.\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.2505 - accuracy: 0.9294 - val_loss: 0.2384 - val_accuracy: 0.9330\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.2414 - accuracy: 0.9321 - val_loss: 0.2318 - val_accuracy: 0.9352\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.2333 - accuracy: 0.9336 - val_loss: 0.2247 - val_accuracy: 0.9369\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 4s 84us/sample - loss: 0.2259 - accuracy: 0.9357 - val_loss: 0.2190 - val_accuracy: 0.9386\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.2189 - accuracy: 0.9382 - val_loss: 0.2142 - val_accuracy: 0.9402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1854c428550>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='SGD',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir.format(timestamp=datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "                                                                            tag='sgd_categorical_crossentropy_1'), histogram_freq=1)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          epochs=EPOCHS,\n",
    "          verbose=VERBOSE,\n",
    "          validation_split=VALIDATION_SPLIT,\n",
    "           callbacks=[tensorboard_callback]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "  128/48000 [..............................] - ETA: 20:35 - loss: 0.1835 - accuracy: 0.9453WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.167040). Check your callbacks.\n",
      "48000/48000 [==============================] - 10s 202us/sample - loss: 0.1921 - accuracy: 0.9433 - val_loss: 0.1386 - val_accuracy: 0.9606\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 0.1166 - accuracy: 0.9643 - val_loss: 0.1159 - val_accuracy: 0.9660\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 105us/sample - loss: 0.0835 - accuracy: 0.9745 - val_loss: 0.0975 - val_accuracy: 0.9727\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0635 - accuracy: 0.9799 - val_loss: 0.0997 - val_accuracy: 0.9711\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.0491 - accuracy: 0.9849 - val_loss: 0.0880 - val_accuracy: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1855af24160>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='RMSProp',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir.format(timestamp=datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "                                                                            tag='RMSProp_categorical_crossentropy_1'), histogram_freq=1)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          epochs=EPOCHS,\n",
    "          verbose=VERBOSE,\n",
    "          validation_split=VALIDATION_SPLIT,\n",
    "           callbacks=[tensorboard_callback]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "  128/48000 [..............................] - ETA: 12:18 - loss: 0.0126 - accuracy: 1.0000WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.122529). Check your callbacks.\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 0.0419 - accuracy: 0.9868 - val_loss: 0.0896 - val_accuracy: 0.9761\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 0.0288 - accuracy: 0.9911 - val_loss: 0.1019 - val_accuracy: 0.9725\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.0994 - val_accuracy: 0.9732\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.0950 - val_accuracy: 0.9774\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.0993 - val_accuracy: 0.9746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1855b1fdf60>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir.format(timestamp=datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "                                                                            tag='Adam_categorical_crossentropy_1'), histogram_freq=1)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          epochs=EPOCHS,\n",
    "          verbose=VERBOSE,\n",
    "          validation_split=VALIDATION_SPLIT,\n",
    "           callbacks=[tensorboard_callback]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_layer (Dense)          (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_layer2 (Dense)         (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_layer3 (Dense)         (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(N_HIDDEN, \n",
    "                                input_shape=(RESHAPED,),\n",
    "                                name='dense_layer', \n",
    "                                activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(N_HIDDEN, \n",
    "                                input_shape=(RESHAPED,),\n",
    "                                name='dense_layer2', \n",
    "                                activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(NB_CLASSES, \n",
    "                                input_shape=(RESHAPED,),\n",
    "                                name='dense_layer3', \n",
    "                                activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "  128/48000 [..............................] - ETA: 17:52 - loss: 2.5458 - accuracy: 0.1250WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.171541). Check your callbacks.\n",
      "48000/48000 [==============================] - 9s 191us/sample - loss: 0.7996 - accuracy: 0.8005 - val_loss: 0.3082 - val_accuracy: 0.9146\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 0.2744 - accuracy: 0.9217 - val_loss: 0.2209 - val_accuracy: 0.9382\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.2103 - accuracy: 0.9383 - val_loss: 0.1928 - val_accuracy: 0.9439\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.1731 - accuracy: 0.9490 - val_loss: 0.1628 - val_accuracy: 0.9529\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.1453 - accuracy: 0.9574 - val_loss: 0.1425 - val_accuracy: 0.9592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1855bb600f0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir.format(timestamp=datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "                                                                            tag='Adam_categorical_crossentropy__sigmoid_1'), histogram_freq=1)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          epochs=EPOCHS,\n",
    "          verbose=VERBOSE,\n",
    "          validation_split=VALIDATION_SPLIT,\n",
    "           callbacks=[tensorboard_callback]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_layer (Dense)          (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_layer2 (Dense)         (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_layer3 (Dense)         (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "REG_L = 0.1\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(N_HIDDEN, \n",
    "                                input_shape=(RESHAPED,),\n",
    "                                name='dense_layer', \n",
    "                                activation='relu',\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l=REG_L)))\n",
    "model.add(tf.keras.layers.Dense(N_HIDDEN, \n",
    "                                input_shape=(RESHAPED,),\n",
    "                                name='dense_layer2', \n",
    "                                activation='relu',\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l=REG_L)))\n",
    "model.add(tf.keras.layers.Dense(NB_CLASSES, \n",
    "                                input_shape=(RESHAPED,),\n",
    "                                name='dense_layer3', \n",
    "                                activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "  128/48000 [..............................] - ETA: 15:21 - loss: 37.1312 - accuracy: 0.0938WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.159044). Check your callbacks.\n",
      "48000/48000 [==============================] - 11s 223us/sample - loss: 4.4048 - accuracy: 0.7837 - val_loss: 1.2269 - val_accuracy: 0.8328\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 1.1351 - accuracy: 0.8438 - val_loss: 1.0648 - val_accuracy: 0.8453\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.0117 - accuracy: 0.8549 - val_loss: 0.9318 - val_accuracy: 0.8785\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 0.9379 - accuracy: 0.8613 - val_loss: 0.9128 - val_accuracy: 0.8583\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 8s 166us/sample - loss: 0.8876 - accuracy: 0.8666 - val_loss: 0.8361 - val_accuracy: 0.8824\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.8476 - accuracy: 0.8702 - val_loss: 0.8406 - val_accuracy: 0.8588\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 9s 193us/sample - loss: 0.8138 - accuracy: 0.8758 - val_loss: 0.7807 - val_accuracy: 0.8834\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 11s 230us/sample - loss: 0.7887 - accuracy: 0.8782 - val_loss: 0.7492 - val_accuracy: 0.8903\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 11s 222us/sample - loss: 0.7672 - accuracy: 0.8797 - val_loss: 0.7353 - val_accuracy: 0.8900\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 9s 179us/sample - loss: 0.7462 - accuracy: 0.8827 - val_loss: 0.7233 - val_accuracy: 0.8919\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 10s 203us/sample - loss: 0.7283 - accuracy: 0.8866 - val_loss: 0.6979 - val_accuracy: 0.8941\n",
      "Epoch 12/50\n",
      "39168/48000 [=======================>......] - ETA: 1s - loss: 0.7129 - accuracy: 0.8890"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir.format(timestamp=datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "                                                                            tag='Adam_categorical_crossentropy_l2_0.1_1'), histogram_freq=1)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          epochs=EPOCHS,\n",
    "          verbose=VERBOSE,\n",
    "          validation_split=VALIDATION_SPLIT,\n",
    "           callbacks=[tensorboard_callback]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REG_L = 0.01\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(N_HIDDEN, \n",
    "                                input_shape=(RESHAPED,),\n",
    "                                name='dense_layer', \n",
    "                                activation='relu',\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l=REG_L)))\n",
    "model.add(tf.keras.layers.Dense(N_HIDDEN, \n",
    "                                input_shape=(RESHAPED,),\n",
    "                                name='dense_layer2', \n",
    "                                activation='relu',\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l=REG_L)))\n",
    "model.add(tf.keras.layers.Dense(NB_CLASSES, \n",
    "                                input_shape=(RESHAPED,),\n",
    "                                name='dense_layer3', \n",
    "                                activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir.format(timestamp=datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "                                                                            tag='Adam_categorical_crossentropy_l2_0.01_1'), histogram_freq=1)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          epochs=EPOCHS,\n",
    "          verbose=VERBOSE,\n",
    "          validation_split=VALIDATION_SPLIT,\n",
    "           callbacks=[tensorboard_callback]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REG_L = 0.001\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(N_HIDDEN, \n",
    "                                input_shape=(RESHAPED,),\n",
    "                                name='dense_layer', \n",
    "                                activation='relu',\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l=REG_L)))\n",
    "model.add(tf.keras.layers.Dense(N_HIDDEN, \n",
    "                                input_shape=(RESHAPED,),\n",
    "                                name='dense_layer2', \n",
    "                                activation='relu',\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l=REG_L)))\n",
    "model.add(tf.keras.layers.Dense(NB_CLASSES, \n",
    "                                input_shape=(RESHAPED,),\n",
    "                                name='dense_layer3', \n",
    "                                activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir.format(timestamp=datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "                                                                            tag='Adam_categorical_crossentropy_l2_0.001_1'), histogram_freq=1)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          epochs=EPOCHS,\n",
    "          verbose=VERBOSE,\n",
    "          validation_split=VALIDATION_SPLIT,\n",
    "           callbacks=[tensorboard_callback]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir C:\\cmder\\logs\\fit (started 2 days, 6:16:40 ago; pid 10080)\n",
      "Selecting TensorBoard with logdir C:\\cmder\\logs\\fit (started 2 days, 6:16:40 ago; port 6006, pid 10080).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-183360ebf1211be8\" width=\"100%\" height=\"1000\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-183360ebf1211be8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list()\n",
    "notebook.display(port=6006, height=1000) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
